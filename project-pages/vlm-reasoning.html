<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <link rel="icon" href="../assets/images/vlm_reasoning_logo.png" />
  <title>Reasoning in Vision-Language Models</title>
  <meta name="description" content="Exploring logical reasoning in VLMs through abductive tasks." />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="../css/layout.css">
  <link rel="stylesheet" href="../css/typography.css">
  <link rel="stylesheet" href="../css/utilities.css">
  <script defer src="../js/script.js"></script>
</head>
<body>
  <div class="navbar">
    <a class="nav-title-link" href="../index.html">
      <span class="nav-title">Shachaf Chaviv</span>
      <a class="button" href="mailto:shachaf.haviv@gmail.com">
        <span class="button-text">Contact Me</span>
      </a>
    </a>
  </div>

  <div id="main-content">
    <div id="project-header">
      <div class="main-title">Reasoning in Vision-Language Models</div>
      <div class="body-text">Evaluated the reasoning ability of VLMs using visual abductive tasks and a custom dataset across styles and prompts.</div>
      <image class="project-header-image" src="../assets/images/vlm_reasoning_logo.png">
    </div>

    <div id="project-details">
      <div class="subheader-text">Project Details / Background</div>
      <div class="project-details-content">
        <div class="body-text">
          This project investigated the reasoning capacity of modern Vision-Language Models (VLMs) by presenting them with abductive visual inference tasks. A custom dataset was created featuring a range of scenarios and visual styles including sketches, anime, paper cuts, and photo-realism.
        </div>
        <div class="body-text">
          Prompt engineering played a central role in evaluating how different phrasing affected the models’ outputs. The analysis revealed a significant bias in most models toward selecting the first hypothesis presented—regardless of plausibility—highlighting issues in reasoning and response consistency. The work offered insights into current VLM limitations and directions for improvement.
        </div>
      </div>
    </div>

    <div id="project-gallery">
      <div class="subheader-text"></div>
      <div class="project-gallery-content">
        <div class="gallery-image-container">
          <img src="../assets/images/VLM Poster.pdf" class="gallery-image">
          <span class="image-caption">Poster summarizing the VLM reasoning project.</span>
        </div>
        <div class="gallery-image-container half-width">
          <img src="../assets/images/vlm_examples_grid.png" class="gallery-image">
          <span class="image-caption">Example hypotheses and visual representations tested.</span>
        </div>
      </div>
    </div>
  </div>

  <div id="footer">
    <a class="icon-link" href="mailto:shachaf.haviv@gmail.com">
      <image src="../assets/icons/mail.svg" class="footer-icon"/>
    </a>
  </div>
</body>
</html>
